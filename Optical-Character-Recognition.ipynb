{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical-Character-Recognition \n",
    "A keras based module for trainning and Recognizing the synthetic charecter and then pridict the word using RCNN network\n",
    "## Getting Started\n",
    "The modeule can creatre RCNN model and it can train the model. using method of the call this modele can pridict the charecter in the image and then it makes word from cherecter after doing that it can mark all the word in image and produce a output again it create a folder containing name of that word in move the cropped word into it. size of moved image will be 64x64 for each word.\n",
    "\n",
    "### Class Structure\n",
    "\n",
    "Nural_network\n",
    "- labels_class [veriable]\n",
    "- class_count [veriable]\n",
    "- sample_count [veriable]\n",
    "- sample_dimension [veriable]\n",
    "- isModel [veriable]\n",
    "- isTrained [veriable]\n",
    "- train_data [veriable]\n",
    "- train_labels [veriable]\n",
    "- __init __\n",
    "- getTrainingData\n",
    "- getValidData\n",
    "- model\n",
    "- __shape\n",
    "- Train\n",
    "- load\n",
    "- save\n",
    "- __key_func\n",
    "\n",
    "### Prerequisites\n",
    "For woring with this file you need to install the following library in system\n",
    "- [Python](https://www.python.org)\n",
    "- [numpy](http://www.numpy.org) \n",
    "  - pip install opencv-python\n",
    "- [keras](https://keras.io)\n",
    "  - pip install keras\n",
    "- [Tensorflow](https://www.tensorflow.org)\n",
    "  - pip install tensorflow\n",
    "- [cv2](https://pypi.org/project/opencv-python). Visit [GitHub](https://github.com/skvark/opencv-python) \n",
    "  - pip install opencv-contrib-python\n",
    "- Cherecter dataset\n",
    "   - given with project\n",
    "\n",
    "### Operating System Support\n",
    "- Windows\n",
    "- Linux \n",
    "\n",
    "### Installing\n",
    "\n",
    "**No need to install in system. Copy this file where you want to run**\n",
    "\n",
    "Type ```pip install --``` if you are using native python installation and for anaconda distrubution use ```conda install --``` to install this pakage.\n",
    "\n",
    "### Supported Python versions\n",
    "\n",
    "- 3.5\n",
    "- 3.6\n",
    "- 3.7\n",
    "\n",
    "### Running\n",
    "***Create a model and train it:***\n",
    "```\n",
    "nn = Nural_network()\n",
    "nn.model()\n",
    "nn.Train()\n",
    "nn.save()\n",
    "nn.model.summary()\n",
    "```\n",
    "***Load the pre existing model:***\n",
    "```\n",
    "nn = Nural_network()\n",
    "nn.load()\n",
    "nn.Train()\n",
    "nn.save()\n",
    "nn.model.summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import keras module\n",
    "\"\"\"\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Flatten, Conv2D, MaxPooling1D, LSTM, RNN, Dropout\n",
    "from keras.layers import Reshape, Lambda, BatchNormalization\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\"\"\"\n",
    "import misc packages\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nural_network:\n",
    "    \"\"\"\n",
    "        RCNN nural network module\n",
    "    \"\"\"\n",
    "    def __init__(self, ):\n",
    "        \"\"\"\n",
    "        __init__ *None*\n",
    "        @return: None\n",
    "        \"\"\"\n",
    "#         Total Label available\n",
    "        self.labels_class = np.array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'])\n",
    "        \n",
    "#         Number of class\n",
    "        self.class_count = 62\n",
    "    \n",
    "#         No of sample in each class\n",
    "        self.sample_count = 1016\n",
    "    \n",
    "#         Obsoleted; privously used in open cv\n",
    "        self.sample_dimension = 128\n",
    "    \n",
    "#         Status flag\n",
    "        self.isModel = False\n",
    "        self.isTrained = False\n",
    "        \n",
    "#         Data\n",
    "        self.train_data, self.train_labels = [],[]\n",
    "        print(\"__init__\")\n",
    "    \n",
    "    def getTrainingData(self, root, i):\n",
    "        \"\"\"\n",
    "            getTrainingData(root, i):\n",
    "            root *string* : base path where the row feature data is available\n",
    "            i *int*: serial number of extrected row file\n",
    "            @return: None\n",
    "            @update: self.train_data, self.train_labels\n",
    "        \n",
    "        \"\"\"\n",
    "#         read training file; feature data\n",
    "        f = open(root+os.sep+\"data_\"+i, 'r')\n",
    "        val = f.read()\n",
    "        self.train_data = np.array(eval(val))\n",
    "        f.close()\n",
    "        \n",
    "#         corresponding label \n",
    "        f = open(root+os.sep+\"lable_\"+i, 'r')\n",
    "        lab = f.read()\n",
    "        self.train_labels = np.array(eval(lab))\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "    def getValidData(self, root):\n",
    "        \"\"\"\n",
    "            getValidData(root): select a random set for valid data set\n",
    "            root *string* : base path where the row feature data is available\n",
    "            @return: None\n",
    "            @update: self.valid_data, self.valid_labels\n",
    "        \n",
    "        \"\"\"\n",
    "#         read training file; feature data\n",
    "        valid_set = random.randint(1,6)\n",
    "        print('valid set : '+str(valid_set))\n",
    "        f = open(root+os.sep+\"data_\"+str(valid_set), 'r')\n",
    "        val = f.read()\n",
    "        self.valid_data = np.array(eval(val))\n",
    "        f.close()\n",
    "        \n",
    "#         corresponding label \n",
    "        f = open(root+os.sep+\"lable_\"+str(valid_set), 'r')\n",
    "        lab = f.read()\n",
    "        self.valid_labels = np.array(eval(lab))\n",
    "        f.close()\n",
    "        \n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "            Create a model if not created.\n",
    "            \n",
    "            _________________________________________________________________\n",
    "            Layer (type)                 Output Shape              Param #   \n",
    "            =================================================================\n",
    "            conv2d_1 (Conv2D)            (None, 4, 1, 256)         6400      \n",
    "            _________________________________________________________________\n",
    "            reshape (Reshape)            (None, 8, 128)            0         \n",
    "            _________________________________________________________________\n",
    "            lstm_1 (LSTM)                (None, 8, 128)            131584    \n",
    "            _________________________________________________________________\n",
    "            flatten_1 (Flatten)          (None, 1024)              0         \n",
    "            _________________________________________________________________\n",
    "            dense_1 (Dense)              (None, 62)                63550     \n",
    "            =================================================================\n",
    "            Total params: 201,534\n",
    "            Trainable params: 201,534\n",
    "            Non-trainable params: 0\n",
    "            _________________________________________________________________\n",
    "            None\n",
    "            \n",
    "            @return: None\n",
    "            @update: self.model\n",
    "        \"\"\"\n",
    "        if not self.isModel:\n",
    "            self.isModel = True\n",
    "            self.model = Sequential()\n",
    "            self.model.add(Conv2D(256, (2, 2),  input_shape=(5, 2, 6), activation='relu'))\n",
    "            self.model.add(Reshape(target_shape=((8, 128)), name='reshape'))\n",
    "            self.model.add(LSTM(128, return_sequences=True))\n",
    "            self.model.add(Flatten())\n",
    "            self.model.add(Dense(self.class_count, activation='softmax'))\n",
    "            self.model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    \n",
    "    def __shape(self, data):\n",
    "        \"\"\"\n",
    "            __shape(data): return the data reshape within range -1 to 1\n",
    "            data *numpy array* : base path where the row feature data is available\n",
    "            @return: numpy array [-1, 1]\n",
    "        \n",
    "        \"\"\"\n",
    "#         Shape data in range -1 to 1\n",
    "        for i in range(0, 6):\n",
    "            data[:, :, i] = scale( data[:, :, i], axis=0, with_mean=True, with_std=True, copy=True )\n",
    "        return np.reshape(data, (len(data),5,2,6))\n",
    "    \n",
    "    def Train(self, path='extracted', save_progress=False):\n",
    "        \"\"\"\n",
    "            Train(path='extracted', save_progress=False)): train the model\n",
    "            path='extracted' *string* : base path for training data\n",
    "            save_progress=False *boolean*: weather you want to save the model after complition of each set.\n",
    "            @return: None\n",
    "            @update: self.isTrained = True\n",
    "        \n",
    "        \"\"\"\n",
    "        self.isTrained = True\n",
    "        for i in range(1, 128):\n",
    "#             Total 64 file 1016/8 = 127\n",
    "            print(\"Trainning Set : \"+str(i))\n",
    "    \n",
    "#             Load the training data \n",
    "            self.getTrainingData(path, str(i))\n",
    "            self.getValidData(path)\n",
    "        \n",
    "            self.train_data = self.__shape(self.train_data)\n",
    "            self.valid_data = self.__shape(self.valid_data)\n",
    "        \n",
    "            print(self.train_data.shape)\n",
    "            \n",
    "            self.model.fit(self.train_data, self.train_labels, validation_data=(self.valid_data, self.valid_labels), epochs=100, batch_size=10)\n",
    "            if save_progress:\n",
    "                self.save()\n",
    "        \n",
    "    def load(self, path=\"feature.bin\"):\n",
    "        \"\"\"\n",
    "            load(path=\"feature.bin\"): load pre-saved keras model\n",
    "            path=\"feature.bin\" *string* : filename with proper path information(relative path|abslute path) which will load in model\n",
    "            @return: None\n",
    "            @update: self.isTrained, self.isModel\n",
    "        \n",
    "        \"\"\"\n",
    "#         Load the saved model\n",
    "        self.isTrained = True\n",
    "        self.isModel = True\n",
    "        self.model = load_model(path)\n",
    "        \n",
    "    def save(self, path=\"feature.bin\"):\n",
    "        \"\"\"\n",
    "            save(path=\"feature.bin\"): Save the current trainned keras model\n",
    "            path=\"feature.bin\" *string* : filename with proper path information(relative path|abslute path) where the file will save\n",
    "            @return: None\n",
    "        \n",
    "        \"\"\"\n",
    "#         Save the model\n",
    "        self.model.save(path)\n",
    "    \n",
    "    def __key_func(self, x):\n",
    "        \"\"\"\n",
    "            __key_func(x): Sort the file and folder by alphabetical order.\n",
    "            x *list* : list of file and folder that you want to sort\n",
    "            @return: list\n",
    "        \n",
    "        \"\"\"\n",
    "#         Function for sorting file in directory python \"os\"\n",
    "        pat=re.compile(\"(\\d+)\\D*$\")\n",
    "        mat=pat.search(os.path.split(x)[-1]) # match last group of digits\n",
    "        if mat is None:\n",
    "            return x\n",
    "        return \"{:>10}\".format(mat.group(1)) # right align to 10 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__\n"
     ]
    }
   ],
   "source": [
    "nn = Nural_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nn.load()\n",
    "nn.model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn.Train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 4, 1, 256)         6400      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8, 128)            131584    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 62)                63550     \n",
      "=================================================================\n",
      "Total params: 201,534\n",
      "Trainable params: 201,534\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(nn.model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
